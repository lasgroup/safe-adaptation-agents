defaults:
  agent: vanilla_policy_gradients
  safe: True
  robot: point
  cost_limit: 25
  log_dir: results
  seed: 0
  time_limit: 1000
  epochs: 200
  eval_every: 5
  eval_trials: 5
  train_driver: {adaptation_steps: 5000, query_steps: 2000}
  test_driver: {adaptation_steps: 5000, query_steps: 2000}
  action_repeat: 1
  render_episodes: 1
  render_options: {camera_id: 'fixedfar'}
  render_mode: rgb_array
  jit: True
  precision: 32
  parallel_envs: 10

no_adaptation:
  task: go_to_goal
  train_driver: {adaptation_steps: 30000, query_steps: 0}
  test_driver: {adaptation_steps: 0, query_steps: 10000}
  eval_trials: 1
  task_batch_size: 1
  epochs: 334

vanilla_policy_gradients:
  entropy_regularization: 0.
  vf_iters: 5
  pi_iters: 1
  actor: {layers: [32, 32], min_stddev: 0.01, max_stddev: 10., activation: jnn.tanh, initialization: glorot, squash: False, heteroscedastic: False}
  critic: {layers: [32, 32], dist: normal, activation: jnn.tanh, name: 'critic', initialization: glorot}
  discount: 0.99
  lambda_: 0.97
  num_trajectories: 30
  actor_opt: {lr: 0.01, eps: 1e-8}
  critic_opt: {lr: 0.01, eps: 1e-8}

ppo_lagrangian:
  entropy_regularization: 0.
  vf_iters: 80
  pi_iters: 80
  actor: {layers: [256, 256], min_stddev: 0.01, max_stddev: 10., activation: jnn.tanh, initialization: glorot, squash: False, heteroscedastic: False}
  critic: {layers: [256, 256], dist: normal, activation: jnn.tanh, name: 'critic', initialization: glorot}
  discount: 0.99
  lambda_: 0.97
  cost_discount: 0.99
  num_trajectories: 30
  actor_opt: {lr: 3e-4, eps: 1e-5, clip: 0.5}
  critic_opt: {lr: 1e-3, eps: 1e-5, clip: 0.5}
  lagrangian_opt: {lr: 5e-2, eps: 1e-5, clip: 0.5}
  clip_ratio: 0.2
  kl_margin: 1.2
  target_kl: 0.01
  initial_lagrangian: 1.

domain_randomization:
  train_driver: {adaptation_steps: 10000, query_steps: 10000}
  test_driver: {adaptation_steps: 10000, query_steps: 10000}
  eval_trials: 1
  task_batch_size: 10
  epochs: 1000

maml_ppo_lagrangian:
  entropy_regularization: 0.
  vf_iters: 80
  pi_iters: 80
  actor: {layers: [256, 256], min_stddev: 0.01, max_stddev: 10., activation: jnn.tanh, initialization: glorot, squash: False, heteroscedastic: False}
  critic: {layers: [256, 256], dist: normal, activation: jnn.tanh, name: 'critic', initialization: glorot}
  discount: 0.99
  lambda_: 1.0
  cost_discount: 0.99
  num_trajectories: 10
  num_query_trajectories: 10
  actor_opt: {lr: 1e-3, eps: 1e-5}
  critic_opt: {lr: 1e-3, eps: 1e-5}
  lagrangian_opt: {lr: 5e-2, eps: 1e-5}
  clip_ratio: 0.2
  kl_margin: 1.2
  target_kl: 0.01
  initial_lagrangian: 1.
  lagrangian_inner_lr: 0.1
  policy_inner_lr: 0.1
  inner_lr_opt: {lr: 0.}
  inner_steps: 1

